# Projet Deep Learning ‚Äî Classification du risque de cancer du sein (Low / Medium / High)

**√âtudiante :** GOKSEN Betul  
**Notebook :** `cancer_risk_classification_notebook.ipynb`  
**Dataset :** `cancer-risk-factors.csv`

---

## 1) Pr√©sentation du projet
Dans le cadre de ce DM, j‚Äôai travaill√© sur un cas d‚Äôusage inspir√© d‚Äôun contexte r√©el de **cabinet m√©dical**.  
L‚Äôobjectif est d‚Äôaider les m√©decins √† ne plus se baser uniquement sur l‚Äô√¢ge pour recommander un d√©pistage, mais d‚Äôutiliser une approche **multifactorielle** (facteurs de sant√©, mode de vie, ant√©c√©dents, etc.).

Le mod√®le doit classer les patientes selon trois niveaux de risque :
- **Low**
- **Medium**
- **High**

---

## 2) Priorit√© : s√©curit√© avant accuracy
Dans le m√©dical, l‚Äôerreur la plus critique est de **ne pas d√©tecter une patiente ‚ÄúHigh Risk‚Äù** (faux n√©gatif).  
C‚Äôest pourquoi l‚Äôaccuracy globale n‚Äôest pas l‚Äôindicateur principal ici.

üéØ **Objectif principal du projet : maximiser le Recall sur la classe ‚ÄúHigh‚Äù (viser 100%)**, quitte √† g√©n√©rer davantage de faux positifs (sur-d√©pistage).

---

## 3) D√©marche (cycle de projet type CRISP-DM)
### 3.1 Pr√©paration des donn√©es
- **Filtrage** : conservation uniquement des cas li√©s au **cancer du sein** pour √™tre coh√©rent avec la demande.
- **Nettoyage** : suppression des doublons et retrait des colonnes non pertinentes (ex. `Patient_ID`).
- **Normalisation** : standardisation des variables (via `StandardScaler`) afin de mettre des features comme l‚Äô√¢ge, l‚ÄôIMC, etc. sur la m√™me √©chelle.

### 3.2 Gestion du d√©s√©quilibre des classes (d√©fi principal)
Le dataset est fortement d√©s√©quilibr√© (tr√®s peu de cas **High**).

- Le premier mod√®le (ANN classique) est p√©nalis√© par ce d√©s√©quilibre et d√©tecte mal la classe ‚ÄúHigh‚Äù.
- J‚Äôai donc test√© des approches de r√©√©quilibrage :
  - **SMOTE**
  - **SMOTE-Tomek**
Ces techniques sont appliqu√©es uniquement sur l‚Äôentra√Ænement, afin de pr√©server un test set r√©aliste.

### 3.3 Choix du mod√®le et optimisation
Apr√®s comparaison, le mod√®le le plus robuste et stable est :
- **Balanced Random Forest**

J‚Äôai ensuite ajout√© un point cl√© du projet :
- **Threshold tuning** : ajustement manuel du seuil de d√©cision pour forcer une d√©tection maximale des cas ‚ÄúHigh‚Äù.
Objectif : **0 faux n√©gatif sur High**, m√™me si cela augmente l√©g√®rement les fausses alertes.

### 3.4 Explicabilit√© (SHAP)
Un m√©decin doit pouvoir comprendre la d√©cision : un mod√®le ‚Äúbo√Æte noire‚Äù est difficilement utilisable.

J‚Äôai int√©gr√© **SHAP** pour :
- analyser l‚Äôimportance globale des variables,
- expliquer **au cas par cas** pourquoi une patiente est class√©e ‚ÄúHigh‚Äù.

---

## 4) R√©sultats (synth√®se)
- ‚úÖ **Recall (High Risk) : 100%** (aucune patiente √† haut risque n‚Äôest oubli√©e)
- ‚úÖ **F1-score global : ~0.95** (selon configuration/seed)
- ‚úÖ **Interpr√©tabilit√©** : d√©cisions justifi√©es via SHAP (global + individuel)

> Remarque : les performances peuvent l√©g√®rement varier selon la s√©paration train/test et les param√®tres, mais l‚Äôobjectif prioritaire reste le Recall High.

---

## 5) Fichiers g√©n√©r√©s par le notebook
Le notebook sauvegarde des figures au format `.png` et cr√©e un fichier `figures.zip` contenant toutes les images.

Exemples de figures g√©n√©r√©es (noms conserv√©s tels quels) :
- `class_distribution.png`
- `correlation_matrix.png`
- `confusion_matrix_initial.png`
- `confusion_matrix_class_weight.png`
- `confusion_matrix_final.png`
- `threshold_analysis.png`
- `shap_summary_bar.png`
- `shap_summary_beeswarm.png`
- `shap_force_high_risk.png`
- `shap_waterfall_high_risk.png`
- `model_comparison.png`
- `figures.zip`

---

## 6) Ex√©cution du projet
### Pr√©requis
- Python 3.9+ recommand√©
- Jupyter Notebook / JupyterLab

### Installation des d√©pendances
```bash
pip install numpy pandas matplotlib scikit-learn imbalanced-learn tensorflow shap
